import asyncio
import websockets
import serial
import json
import cv2
import base64
import tensorflow as tf
import numpy as np

# Configuración del puerto serie
PORT = '/dev/rfcomm0'  # Puerto UART
BAUDRATE = 9600        # Velocidad de comunicación UART

# Cargar el modelo de TensorFlow (.h5)
MODEL_PATH = "model.h5"  # Ruta al modelo TensorFlow
model = tf.keras.models.load_model(MODEL_PATH)
print(f"Modelo cargado desde {MODEL_PATH}")

# Inicializar conexión serie
def init_serial():
    try:
        ser = serial.Serial(PORT, BAUDRATE, timeout=1)
        print(f"Conectado al puerto {PORT} a {BAUDRATE} baudios.")
        return ser
    except Exception as e:
        print(f"Error al conectar con el puerto serie: {e}")
        return None

def preprocess_frame(frame):
    """
    Preprocesa el frame para que sea compatible con el modelo.
    - Cambia el tamaño del frame.
    - Normaliza los valores de los píxeles.
    """
    input_size = (224, 224)  # Tamaño de entrada del modelo (ajustar si es necesario)
    resized_frame = cv2.resize(frame, input_size)  # Redimensiona el frame
    normalized_frame = resized_frame / 255.0  # Normaliza los valores de los píxeles
    return np.expand_dims(normalized_frame, axis=0)  # Añade la dimensión batch

def draw_detections(frame, detections):
    """
    Dibuja las detecciones en el frame.
    - Se asume que `detections` contiene coordenadas y etiquetas.
    """
    for detection in detections:
        x, y, w, h, label = detection
        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
        cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    return frame

async def capture_video_and_send(websocket):
    """
    Captura video en vivo desde la cámara, realiza detecciones y transmite los resultados al servidor WebSocket.
    """
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("Error al abrir la cámara.")
        return

    while True:
        ret, frame = cap.read()
        if not ret:
            print("Error al leer el frame de la cámara.")
            break

        # Realiza el preprocesamiento del frame
        input_data = preprocess_frame(frame)

        # Realiza la predicción con el modelo
        predictions = model.predict(input_data)

        # Procesa las predicciones para obtener coordenadas y etiquetas
        # Este paso depende de tu modelo y cómo genera las salidas
        # Aquí se muestra un ejemplo ficticio:
        detections = []
        for i, prediction in enumerate(predictions[0]):
            if prediction[4] > 0.5:  # Umbral de confianza
                x, y, w, h = prediction[:4]
                label = f"Clase {int(prediction[5])}"  # Etiqueta
                detections.append((int(x), int(y), int(w), int(h), label))

        # Dibuja las detecciones en el frame
        frame_with_detections = draw_detections(frame.copy(), detections)

        # Convierte el frame con detecciones a formato base64
        _, buffer = cv2.imencode('.jpg', frame_with_detections)
        encoded_frame = base64.b64encode(buffer).decode('utf-8')

        # Envía el frame con detecciones como un mensaje JSON
        message = {
            'role': 'video',
            'frame': encoded_frame
        }

        try:
            await websocket.send(json.dumps(message))
            await asyncio.sleep(0.05)  # Ajusta la tasa de fotogramas según lo necesites
        except websockets.exceptions.ConnectionClosed:
            print("Conexión cerrada, terminando transmisión de video.")
            break

    cap.release()

async def handle_websocket(ser):
    """
    Maneja la conexión WebSocket y envía los mensajes recibidos al módulo HC-05.
    """
    uri = "ws://192.168.57.75:8080"  # Dirección del servidor WebSocket
    try:
        async with websockets.connect(uri) as websocket:
            print("Conectado al servidor WebSocket.")
            await websocket.send(json.dumps({"role": "video"}))  # Registra el cliente con rol "video"
            print("Rol 'video' registrado en el servidor WebSocket.")
            
            asyncio.create_task(capture_video_and_send(websocket))  # Inicia transmisión de video

            async for message in websocket:
                try:
                    data = json.loads(message)
                    print(f"Mensaje recibido del WebSocket: {data}")

                    if ser and ser.is_open:
                        mensaje_uart = data.get("command")
                        ser.write(mensaje_uart.encode('utf-8'))
                        print(f"Enviado al módulo HC-05: {mensaje_uart}")

                        if ser.in_waiting > 0:
                            respuesta = ser.readline().decode('utf-8').strip()
                            print(f"Respuesta del módulo HC-05: {respuesta}")

                except json.JSONDecodeError:
                    print("Error: mensaje recibido no es un JSON válido.")
    except Exception as e:
        print(f"Error en la conexión WebSocket: {e}")

async def main():
    """
    Inicializa el puerto serie y gestiona la conexión WebSocket.
    """
    ser = init_serial()
    if not ser:
        print("No se pudo inicializar el puerto UART.")
        return

    await handle_websocket(ser)

    if ser and ser.is_open:
        ser.close()
        print("Conexión UART cerrada.")

if __name__ == "__main__":
    asyncio.run(main())
